{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAFLUrut2Z7RrLYPM92HEO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import relevant packages"
      ],
      "metadata": {
        "id": "ascYiYqQc7Tk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "VhpghOMcc10K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "P7u0HQ-ldMva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset , mnist_info = tfds.load(name = 'mnist' , with_info = True , as_supervised = True , try_gcs=True)"
      ],
      "metadata": {
        "id": "3fiXwsCsdPNM"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract train , validation and test dataset"
      ],
      "metadata": {
        "id": "ASy7yGvMedAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train , mnist_test = mnist_dataset['train'] , mnist_dataset['test']\n",
        "\n",
        "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples #gives num of training set samples\n",
        "num_validation_samples = tf.cast(num_validation_samples , tf.int64) #makes sure its integar and not float\n",
        "\n",
        "num_test_samples = mnist_info.splits['test'].num_examples\n",
        "num_test_samples = tf.cast( num_test_samples, tf.int64)\n"
      ],
      "metadata": {
        "id": "NgAXyY0beftg"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling the data"
      ],
      "metadata": {
        "id": "c_Sl3UC3vBsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(image , label) :\n",
        "  image = tf.cast(image , tf.float32)\n",
        "  image/= 255. #making the values between 0-255 into 0's and 1's\n",
        "  return image , label\n",
        "\n",
        "scaled_train_and_validation_dataset = mnist_train.map(scale)\n",
        "test_data = mnist_test.map(scale)\n"
      ],
      "metadata": {
        "id": "HKW3ZQfQvD4_"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffling the data\n",
        "to make batches"
      ],
      "metadata": {
        "id": "cu_-Iol-wIv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size = 10000\n",
        "\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_dataset.shuffle(buffer_size)"
      ],
      "metadata": {
        "id": "mnJILCn9wilG"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract train and validation dataset"
      ],
      "metadata": {
        "id": "tan45KNQx0lH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)"
      ],
      "metadata": {
        "id": "UkJtN8_3x2hF"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making batches"
      ],
      "metadata": {
        "id": "UV2tBHNWzQDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "train_data = train_data.batch(batch_size)\n",
        "validation_data = validation_data.batch(num_validation_samples)\n",
        "test_data = test_data.batch(num_test_samples)\n",
        "\n",
        "validation_inputs , validation_targets = next(iter(validation_data))"
      ],
      "metadata": {
        "id": "E_-qf0F_zRrA"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL"
      ],
      "metadata": {
        "id": "RzIEg92m2RW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outline the model"
      ],
      "metadata": {
        "id": "ZBXUrMfF2WR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "output_size = 10\n",
        "hidden_layer_size = 200 #arbitrary\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([                                                                           #stacks layers\n",
        "\n",
        "                            tf.keras.layers.Flatten(input_shape=(28,28,1)) ,\n",
        "                            tf.keras.layers.Dense(hidden_layer_size , activation='relu') , \n",
        "                            tf.keras.layers.Dense(hidden_layer_size , activation='relu') , \n",
        "                            tf.keras.layers.Dense(hidden_layer_size , activation ='tanh') ,\n",
        "                            tf.keras.layers.Dense(output_size , activation = 'softmax')\n",
        "\n",
        "])           "
      ],
      "metadata": {
        "id": "t9m1s59v2Vrv"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Choose the optimizer and the loss function"
      ],
      "metadata": {
        "id": "m1j-BqUH5_Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics =['accuracy'])   #sparse_categorical_crossentropy applies one hot encoding on th\n"
      ],
      "metadata": {
        "id": "-qCBLTUo6DWI"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "DVbmzJPj_aI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "model.fit(train_data , epochs = num_epochs , validation_data = (validation_inputs , validation_targets) , verbose =2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5rt03kE_Y9Y",
        "outputId": "be9cc522-7661-4eec-caee-2c650919d053"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "540/540 - 7s - loss: 0.2477 - accuracy: 0.9251 - val_loss: 0.1372 - val_accuracy: 0.9565 - 7s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "540/540 - 8s - loss: 0.0956 - accuracy: 0.9701 - val_loss: 0.0849 - val_accuracy: 0.9725 - 8s/epoch - 15ms/step\n",
            "Epoch 3/5\n",
            "540/540 - 6s - loss: 0.0647 - accuracy: 0.9799 - val_loss: 0.0742 - val_accuracy: 0.9760 - 6s/epoch - 11ms/step\n",
            "Epoch 4/5\n",
            "540/540 - 7s - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.0614 - val_accuracy: 0.9805 - 7s/epoch - 12ms/step\n",
            "Epoch 5/5\n",
            "540/540 - 6s - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.0405 - val_accuracy: 0.9877 - 6s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac15627450>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ],
      "metadata": {
        "id": "rPAnotEhFiKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss , test_accuracy = model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOCKTZ7CFllH",
        "outputId": "24c2d765-8a2f-4674-a13a-d353dc357113"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0770 - accuracy: 0.9775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy is 97.75%"
      ],
      "metadata": {
        "id": "cUU4VUDpF0qW"
      }
    }
  ]
}